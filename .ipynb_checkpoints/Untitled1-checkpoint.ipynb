{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bf6a4f6-9644-4aa5-a200-bc59814c5d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030   NaN  2.5050    1  273   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90    NaN  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99    NaN  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 206 “Write a program to create a Model using linear regression to predict the price\n",
    "# of house using the csv file provided named “Housing.csv”. Do the required process\n",
    "# in the data before making a model. Find predicted values, co-efficients, intercept and\n",
    "# mean squared error.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv(\"HousingData.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3fd83a6-ae5f-4915-bcb5-742ee17178e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       20\n",
       "ZN         20\n",
       "INDUS      20\n",
       "CHAS       20\n",
       "NOX         0\n",
       "RM          0\n",
       "AGE        20\n",
       "DIS         0\n",
       "RAD         0\n",
       "TAX         0\n",
       "PTRATIO     0\n",
       "B           0\n",
       "LSTAT      20\n",
       "MEDV        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90105f72-5de4-4368-8545-3774ef4cd799",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb984820-2876-484c-8b71-ff3cd7a33d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.isna().sum()\n",
    "x=df.drop('MEDV',axis=1)\n",
    "y=df[\"MEDV\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr=LinearRegression()\n",
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "007d8bf8-34ed-43a9-8398-9b6b5582c655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29.22850199 17.5037472  21.80803847 30.4942528  18.50265527 34.7432311\n",
      " 22.07369779 30.7541295  33.52029866 14.82910783 22.14507214 41.26427356\n",
      " 22.51242483 16.87300668 19.0023074  20.77110711 17.26921288 15.48568273\n",
      " 22.69482862 14.12652975 18.19319969 20.48292217 17.04235173 29.66737037\n",
      " 26.09718411 16.06132841 27.09746911 31.45656662 22.64238912 27.06681913\n",
      " 41.10181897 18.21320236 23.062681   17.41202659 17.39546606 21.076803\n",
      " 22.38598488 21.66963934 22.9118984  20.80249561 27.70046219 34.60121409\n",
      " 22.25931447 30.83868791 35.33229137 19.76393425 24.99195034 10.39133132\n",
      " 19.75538217 25.31114768 21.55934818 25.89776968 14.23212614 18.66822307\n",
      " 18.34126683 24.31756905 43.40891373 22.87668508 15.3452895  23.17268086\n",
      " 21.11796307 21.4821572  14.66508216 28.92300146 -3.71655126 32.60224615\n",
      " 16.81628299 31.90077457 24.78013157 20.11600672 31.55246209 32.35712749\n",
      " 18.87519084 19.5714957  19.26577986 35.60775919 19.34796049 28.48982534\n",
      " 16.32963606]\n",
      "33.65240504056522 -0.112187394111703\n",
      "0.6270849941673184 31.454047664950934\n"
     ]
    }
   ],
   "source": [
    "y_pred=lr.predict(x_test)\n",
    "print(y_pred)\n",
    "print(lr.intercept_,lr.coef_[0])\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "print(r2_score(y_test,y_pred),mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11934d3e-6cf8-4e43-b57e-0c279fdca9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 207 “Write a program to create a Model using linear regression to predict the student\n",
    "# scores using the csv file provided named “student_scores.csv”. Do the required process\n",
    "# in the data before making a model. Find predicted values, co-efficients, intercept and\n",
    "# mean squared error.\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"student_scores.csv\")\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "180f10ba-2d0c-4ed7-aaba-27ada3ce1bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df[['Hours']]\n",
    "y=df['Scores']\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr=LinearRegression()\n",
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "651c24c0-d8b9-4c8a-a735-0ebe0bf152ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83.18814104 27.03208774 27.03208774 69.63323162 59.95115347]\n",
      "2.826892353899737 9.682078154455697\n",
      "18.943211722315272\n"
     ]
    }
   ],
   "source": [
    "y_pred=lr.predict(x_test)\n",
    "print(y_pred)\n",
    "print(lr.intercept_,lr.coef_[0])\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1917b457-7cad-44d9-8cf5-345b3e0b9ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Petrol_tax</th>\n",
       "      <th>Average_income</th>\n",
       "      <th>Paved_Highways</th>\n",
       "      <th>Population_Driver_licence(%)</th>\n",
       "      <th>Petrol_Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3571</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.525</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4092</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.572</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3865</td>\n",
       "      <td>1586</td>\n",
       "      <td>0.580</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.50</td>\n",
       "      <td>4870</td>\n",
       "      <td>2351</td>\n",
       "      <td>0.529</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4399</td>\n",
       "      <td>431</td>\n",
       "      <td>0.544</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.00</td>\n",
       "      <td>5342</td>\n",
       "      <td>1333</td>\n",
       "      <td>0.571</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.00</td>\n",
       "      <td>5319</td>\n",
       "      <td>11868</td>\n",
       "      <td>0.451</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.00</td>\n",
       "      <td>5126</td>\n",
       "      <td>2138</td>\n",
       "      <td>0.553</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4447</td>\n",
       "      <td>8577</td>\n",
       "      <td>0.529</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4512</td>\n",
       "      <td>8507</td>\n",
       "      <td>0.552</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4391</td>\n",
       "      <td>5939</td>\n",
       "      <td>0.530</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.50</td>\n",
       "      <td>5126</td>\n",
       "      <td>14186</td>\n",
       "      <td>0.525</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4817</td>\n",
       "      <td>6930</td>\n",
       "      <td>0.574</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4207</td>\n",
       "      <td>6580</td>\n",
       "      <td>0.545</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4332</td>\n",
       "      <td>8159</td>\n",
       "      <td>0.608</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4318</td>\n",
       "      <td>10340</td>\n",
       "      <td>0.586</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4206</td>\n",
       "      <td>8508</td>\n",
       "      <td>0.572</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3718</td>\n",
       "      <td>4725</td>\n",
       "      <td>0.540</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4716</td>\n",
       "      <td>5915</td>\n",
       "      <td>0.724</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.50</td>\n",
       "      <td>4341</td>\n",
       "      <td>6010</td>\n",
       "      <td>0.677</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4593</td>\n",
       "      <td>7834</td>\n",
       "      <td>0.663</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4983</td>\n",
       "      <td>602</td>\n",
       "      <td>0.602</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4897</td>\n",
       "      <td>2449</td>\n",
       "      <td>0.511</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4258</td>\n",
       "      <td>4686</td>\n",
       "      <td>0.517</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.50</td>\n",
       "      <td>4574</td>\n",
       "      <td>2619</td>\n",
       "      <td>0.551</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3721</td>\n",
       "      <td>4746</td>\n",
       "      <td>0.544</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8.00</td>\n",
       "      <td>3448</td>\n",
       "      <td>5399</td>\n",
       "      <td>0.548</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7.50</td>\n",
       "      <td>3846</td>\n",
       "      <td>9061</td>\n",
       "      <td>0.579</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4188</td>\n",
       "      <td>5975</td>\n",
       "      <td>0.563</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3601</td>\n",
       "      <td>4650</td>\n",
       "      <td>0.493</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3640</td>\n",
       "      <td>6905</td>\n",
       "      <td>0.518</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3333</td>\n",
       "      <td>6594</td>\n",
       "      <td>0.513</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8.00</td>\n",
       "      <td>3063</td>\n",
       "      <td>6524</td>\n",
       "      <td>0.578</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7.50</td>\n",
       "      <td>3357</td>\n",
       "      <td>4121</td>\n",
       "      <td>0.547</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>8.00</td>\n",
       "      <td>3528</td>\n",
       "      <td>3495</td>\n",
       "      <td>0.487</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6.58</td>\n",
       "      <td>3802</td>\n",
       "      <td>7834</td>\n",
       "      <td>0.629</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5.00</td>\n",
       "      <td>4045</td>\n",
       "      <td>17782</td>\n",
       "      <td>0.566</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3897</td>\n",
       "      <td>6385</td>\n",
       "      <td>0.586</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>8.50</td>\n",
       "      <td>3635</td>\n",
       "      <td>3274</td>\n",
       "      <td>0.663</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4345</td>\n",
       "      <td>3905</td>\n",
       "      <td>0.672</td>\n",
       "      <td>968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4449</td>\n",
       "      <td>4639</td>\n",
       "      <td>0.626</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3656</td>\n",
       "      <td>3985</td>\n",
       "      <td>0.563</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4300</td>\n",
       "      <td>3635</td>\n",
       "      <td>0.603</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3745</td>\n",
       "      <td>2611</td>\n",
       "      <td>0.508</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>6.00</td>\n",
       "      <td>5215</td>\n",
       "      <td>2302</td>\n",
       "      <td>0.672</td>\n",
       "      <td>782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4476</td>\n",
       "      <td>3942</td>\n",
       "      <td>0.571</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4296</td>\n",
       "      <td>4083</td>\n",
       "      <td>0.623</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>7.00</td>\n",
       "      <td>5002</td>\n",
       "      <td>9794</td>\n",
       "      <td>0.593</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Petrol_tax  Average_income  Paved_Highways  Population_Driver_licence(%)  \\\n",
       "0         9.00            3571            1976                         0.525   \n",
       "1         9.00            4092            1250                         0.572   \n",
       "2         9.00            3865            1586                         0.580   \n",
       "3         7.50            4870            2351                         0.529   \n",
       "4         8.00            4399             431                         0.544   \n",
       "5        10.00            5342            1333                         0.571   \n",
       "6         8.00            5319           11868                         0.451   \n",
       "7         8.00            5126            2138                         0.553   \n",
       "8         8.00            4447            8577                         0.529   \n",
       "9         7.00            4512            8507                         0.552   \n",
       "10        8.00            4391            5939                         0.530   \n",
       "11        7.50            5126           14186                         0.525   \n",
       "12        7.00            4817            6930                         0.574   \n",
       "13        7.00            4207            6580                         0.545   \n",
       "14        7.00            4332            8159                         0.608   \n",
       "15        7.00            4318           10340                         0.586   \n",
       "16        7.00            4206            8508                         0.572   \n",
       "17        7.00            3718            4725                         0.540   \n",
       "18        7.00            4716            5915                         0.724   \n",
       "19        8.50            4341            6010                         0.677   \n",
       "20        7.00            4593            7834                         0.663   \n",
       "21        8.00            4983             602                         0.602   \n",
       "22        9.00            4897            2449                         0.511   \n",
       "23        9.00            4258            4686                         0.517   \n",
       "24        8.50            4574            2619                         0.551   \n",
       "25        9.00            3721            4746                         0.544   \n",
       "26        8.00            3448            5399                         0.548   \n",
       "27        7.50            3846            9061                         0.579   \n",
       "28        8.00            4188            5975                         0.563   \n",
       "29        9.00            3601            4650                         0.493   \n",
       "30        7.00            3640            6905                         0.518   \n",
       "31        7.00            3333            6594                         0.513   \n",
       "32        8.00            3063            6524                         0.578   \n",
       "33        7.50            3357            4121                         0.547   \n",
       "34        8.00            3528            3495                         0.487   \n",
       "35        6.58            3802            7834                         0.629   \n",
       "36        5.00            4045           17782                         0.566   \n",
       "37        7.00            3897            6385                         0.586   \n",
       "38        8.50            3635            3274                         0.663   \n",
       "39        7.00            4345            3905                         0.672   \n",
       "40        7.00            4449            4639                         0.626   \n",
       "41        7.00            3656            3985                         0.563   \n",
       "42        7.00            4300            3635                         0.603   \n",
       "43        7.00            3745            2611                         0.508   \n",
       "44        6.00            5215            2302                         0.672   \n",
       "45        9.00            4476            3942                         0.571   \n",
       "46        7.00            4296            4083                         0.623   \n",
       "47        7.00            5002            9794                         0.593   \n",
       "\n",
       "    Petrol_Consumption  \n",
       "0                  541  \n",
       "1                  524  \n",
       "2                  561  \n",
       "3                  414  \n",
       "4                  410  \n",
       "5                  457  \n",
       "6                  344  \n",
       "7                  467  \n",
       "8                  464  \n",
       "9                  498  \n",
       "10                 580  \n",
       "11                 471  \n",
       "12                 525  \n",
       "13                 508  \n",
       "14                 566  \n",
       "15                 635  \n",
       "16                 603  \n",
       "17                 714  \n",
       "18                 865  \n",
       "19                 640  \n",
       "20                 649  \n",
       "21                 540  \n",
       "22                 464  \n",
       "23                 547  \n",
       "24                 460  \n",
       "25                 566  \n",
       "26                 577  \n",
       "27                 631  \n",
       "28                 574  \n",
       "29                 534  \n",
       "30                 571  \n",
       "31                 554  \n",
       "32                 577  \n",
       "33                 628  \n",
       "34                 487  \n",
       "35                 644  \n",
       "36                 640  \n",
       "37                 704  \n",
       "38                 648  \n",
       "39                 968  \n",
       "40                 587  \n",
       "41                 699  \n",
       "42                 632  \n",
       "43                 591  \n",
       "44                 782  \n",
       "45                 510  \n",
       "46                 610  \n",
       "47                 524  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 208 “Write a program to create a Model using linear regression to predict the gasconsumption using the csv file provided named \n",
    "# “petrol_consumption.csv”. Do the required process in the data before making a model. Find predicted values, co-efficients,\n",
    "# intercept and mean squared error.\n",
    "df = pd.read_csv(\"petrol_consumption.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c262f626-24d0-4c4e-a4ca-d2887bf1d57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-3.69937459e+01 -5.65355145e-02 -4.38217137e-03  1.34686930e+03]\n",
      "Intercept: 361.45087906652986\n",
      "Mean Squared Error: 4083.255871745388\n"
     ]
    }
   ],
   "source": [
    "x=df.drop('Petrol_Consumption',axis=1)\n",
    "y=df['Petrol_Consumption']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "predicted_gas_consumption = lin_reg.predict(X_test)\n",
    "# Step 6: Calculate coefficients and intercept\n",
    "coefficients = lin_reg.coef_\n",
    "intercept = lin_reg.intercept_\n",
    "print(\"Coefficients:\", coefficients)\n",
    "print(\"Intercept:\", intercept)\n",
    "# Step 7: Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, predicted_gas_consumption)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fe6e5ed-6ef0-48bb-a96d-2ec3a40e2d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODELYEAR</th>\n",
       "      <th>MAKE</th>\n",
       "      <th>MODEL</th>\n",
       "      <th>VEHICLECLASS</th>\n",
       "      <th>ENGINESIZE</th>\n",
       "      <th>CYLINDERS</th>\n",
       "      <th>TRANSMISSION</th>\n",
       "      <th>FUELTYPE</th>\n",
       "      <th>FUELCONSUMPTION_CITY</th>\n",
       "      <th>FUELCONSUMPTION_HWY</th>\n",
       "      <th>FUELCONSUMPTION_COMB</th>\n",
       "      <th>FUELCONSUMPTION_COMB_MPG</th>\n",
       "      <th>CO2EMISSIONS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>ACURA</td>\n",
       "      <td>ILX</td>\n",
       "      <td>COMPACT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>AS5</td>\n",
       "      <td>Z</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>8.5</td>\n",
       "      <td>33</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>ACURA</td>\n",
       "      <td>ILX</td>\n",
       "      <td>COMPACT</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4</td>\n",
       "      <td>M6</td>\n",
       "      <td>Z</td>\n",
       "      <td>11.2</td>\n",
       "      <td>7.7</td>\n",
       "      <td>9.6</td>\n",
       "      <td>29</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>ACURA</td>\n",
       "      <td>ILX HYBRID</td>\n",
       "      <td>COMPACT</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4</td>\n",
       "      <td>AV7</td>\n",
       "      <td>Z</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>48</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>ACURA</td>\n",
       "      <td>MDX 4WD</td>\n",
       "      <td>SUV - SMALL</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6</td>\n",
       "      <td>AS6</td>\n",
       "      <td>Z</td>\n",
       "      <td>12.7</td>\n",
       "      <td>9.1</td>\n",
       "      <td>11.1</td>\n",
       "      <td>25</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>ACURA</td>\n",
       "      <td>RDX AWD</td>\n",
       "      <td>SUV - SMALL</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6</td>\n",
       "      <td>AS6</td>\n",
       "      <td>Z</td>\n",
       "      <td>12.1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>10.6</td>\n",
       "      <td>27</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>2014</td>\n",
       "      <td>VOLVO</td>\n",
       "      <td>XC60 AWD</td>\n",
       "      <td>SUV - SMALL</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>AS6</td>\n",
       "      <td>X</td>\n",
       "      <td>13.4</td>\n",
       "      <td>9.8</td>\n",
       "      <td>11.8</td>\n",
       "      <td>24</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>2014</td>\n",
       "      <td>VOLVO</td>\n",
       "      <td>XC60 AWD</td>\n",
       "      <td>SUV - SMALL</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6</td>\n",
       "      <td>AS6</td>\n",
       "      <td>X</td>\n",
       "      <td>13.2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>25</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>2014</td>\n",
       "      <td>VOLVO</td>\n",
       "      <td>XC70 AWD</td>\n",
       "      <td>SUV - SMALL</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>AS6</td>\n",
       "      <td>X</td>\n",
       "      <td>13.4</td>\n",
       "      <td>9.8</td>\n",
       "      <td>11.8</td>\n",
       "      <td>24</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>2014</td>\n",
       "      <td>VOLVO</td>\n",
       "      <td>XC70 AWD</td>\n",
       "      <td>SUV - SMALL</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6</td>\n",
       "      <td>AS6</td>\n",
       "      <td>X</td>\n",
       "      <td>12.9</td>\n",
       "      <td>9.3</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>2014</td>\n",
       "      <td>VOLVO</td>\n",
       "      <td>XC90 AWD</td>\n",
       "      <td>SUV - STANDARD</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6</td>\n",
       "      <td>AS6</td>\n",
       "      <td>X</td>\n",
       "      <td>14.9</td>\n",
       "      <td>10.2</td>\n",
       "      <td>12.8</td>\n",
       "      <td>22</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1067 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MODELYEAR   MAKE       MODEL    VEHICLECLASS  ENGINESIZE  CYLINDERS  \\\n",
       "0          2014  ACURA         ILX         COMPACT         2.0          4   \n",
       "1          2014  ACURA         ILX         COMPACT         2.4          4   \n",
       "2          2014  ACURA  ILX HYBRID         COMPACT         1.5          4   \n",
       "3          2014  ACURA     MDX 4WD     SUV - SMALL         3.5          6   \n",
       "4          2014  ACURA     RDX AWD     SUV - SMALL         3.5          6   \n",
       "...         ...    ...         ...             ...         ...        ...   \n",
       "1062       2014  VOLVO    XC60 AWD     SUV - SMALL         3.0          6   \n",
       "1063       2014  VOLVO    XC60 AWD     SUV - SMALL         3.2          6   \n",
       "1064       2014  VOLVO    XC70 AWD     SUV - SMALL         3.0          6   \n",
       "1065       2014  VOLVO    XC70 AWD     SUV - SMALL         3.2          6   \n",
       "1066       2014  VOLVO    XC90 AWD  SUV - STANDARD         3.2          6   \n",
       "\n",
       "     TRANSMISSION FUELTYPE  FUELCONSUMPTION_CITY  FUELCONSUMPTION_HWY  \\\n",
       "0             AS5        Z                   9.9                  6.7   \n",
       "1              M6        Z                  11.2                  7.7   \n",
       "2             AV7        Z                   6.0                  5.8   \n",
       "3             AS6        Z                  12.7                  9.1   \n",
       "4             AS6        Z                  12.1                  8.7   \n",
       "...           ...      ...                   ...                  ...   \n",
       "1062          AS6        X                  13.4                  9.8   \n",
       "1063          AS6        X                  13.2                  9.5   \n",
       "1064          AS6        X                  13.4                  9.8   \n",
       "1065          AS6        X                  12.9                  9.3   \n",
       "1066          AS6        X                  14.9                 10.2   \n",
       "\n",
       "      FUELCONSUMPTION_COMB  FUELCONSUMPTION_COMB_MPG  CO2EMISSIONS  \n",
       "0                      8.5                        33           196  \n",
       "1                      9.6                        29           221  \n",
       "2                      5.9                        48           136  \n",
       "3                     11.1                        25           255  \n",
       "4                     10.6                        27           244  \n",
       "...                    ...                       ...           ...  \n",
       "1062                  11.8                        24           271  \n",
       "1063                  11.5                        25           264  \n",
       "1064                  11.8                        24           271  \n",
       "1065                  11.3                        25           260  \n",
       "1066                  12.8                        22           294  \n",
       "\n",
       "[1067 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 209 Write a program to create a Model using linear regression to predict the gas con-\n",
    "# sumption using the csv file provided named “FuelConsumptionCo2.csv”. Do the re-\n",
    "# quired process in the data before making a model. Find predicted values, co-efficients,\n",
    "# intercept and mean squared error. (Wherever required remove null values, convert\n",
    "# categorical data into numeric data) (Print Output wherever required)\n",
    "df = pd.read_csv(\"FuelConsumptionCo2.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1fe64e8-1b76-49ca-97ba-e55d99b842ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MODELYEAR                     int64\n",
       "MAKE                         object\n",
       "MODEL                        object\n",
       "VEHICLECLASS                 object\n",
       "ENGINESIZE                  float64\n",
       "CYLINDERS                     int64\n",
       "TRANSMISSION                 object\n",
       "FUELTYPE                     object\n",
       "FUELCONSUMPTION_CITY        float64\n",
       "FUELCONSUMPTION_HWY         float64\n",
       "FUELCONSUMPTION_COMB        float64\n",
       "FUELCONSUMPTION_COMB_MPG      int64\n",
       "CO2EMISSIONS                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "422a1e05-1c79-431d-9fa0-35dc23f5a93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(df, columns=['MAKE','MODEL', 'VEHICLECLASS', 'TRANSMISSION','FUELTYPE'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f5d6c6a-f3a0-45d9-ac00-2b96a648e7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ 8.29090568e+06  3.21212589e+00  1.07783674e+00 -3.29710558e+00\n",
      " -4.41228368e+00  1.59740033e+01 -5.03478884e+00 -1.28897346e+12\n",
      " -3.08037271e+11 -4.04847493e+11 -1.14489635e+12 -4.36042870e+11\n",
      " -9.88619199e+11 -9.88471246e+11 -9.56319875e+11 -7.09895361e+11\n",
      " -1.57718211e+12 -9.56884588e+11 -6.83131154e+11 -7.29403903e+11\n",
      " -7.32004594e+11 -9.52236561e+11 -1.17037141e+12 -1.14799627e+12\n",
      " -9.39084096e+11 -1.29459263e+12 -2.85258063e+11 -8.21505400e+11\n",
      " -5.32634770e+11 -1.11581419e+12 -9.37473211e+11 -6.83529035e+11\n",
      " -4.40279532e+11 -7.91476289e+11 -7.62282400e+11 -6.46219988e+11\n",
      " -8.78284109e+11 -8.16092883e+11 -4.54564206e+11  1.06542781e+11\n",
      " -5.38839791e+11 -9.19161113e+11 -6.88934877e+11 -5.37937560e+11\n",
      " -7.64489323e+11  1.27669039e+01  7.35793150e+11  3.62458992e+00\n",
      " -2.86961222e+11  2.47829056e+00  2.46077824e+11  2.55300005e+11\n",
      "  2.55300005e+11  1.18839424e+11  1.18839424e+11  6.11708117e+10\n",
      "  6.11708117e+10  6.11708117e+10  6.11708117e+10  6.11708117e+10\n",
      "  6.11708117e+10  1.64106359e+10  4.43876476e+11 -3.55442240e+10\n",
      "  1.17966963e+12  1.01390916e+12  4.43876476e+11 -2.92663221e+10\n",
      "  2.49747283e+11  2.78116013e+11  4.43876476e+11  4.43876476e+11\n",
      "  2.49747283e+11  1.74610312e+11  1.74610312e+11  4.43876476e+11\n",
      "  4.43876476e+11  4.43876476e+11  4.43876476e+11  5.60470616e+10\n",
      "  5.60470616e+10  5.63120266e+09  7.83967569e+11  7.83967569e+11\n",
      "  7.83967569e+11  7.83967569e+11  7.83967569e+11  7.10401777e+11\n",
      "  3.07415896e+11  3.07415896e+11 -1.33160429e+09 -1.02692014e+09\n",
      "  2.49747283e+11  3.07415896e+11  2.49747283e+11  4.43876476e+11\n",
      "  4.18160056e+11 -8.87013761e+07  4.43876476e+11 -2.02396280e+08\n",
      "  2.49747283e+11  2.49747283e+11  2.49747283e+11 -1.46994553e+11\n",
      " -1.46994553e+11 -1.46994553e+11 -1.46994553e+11 -1.46994553e+11\n",
      " -1.46994553e+11 -1.46994553e+11 -1.46994553e+11  5.85479009e+10\n",
      " -1.46994553e+11 -1.46994553e+11  1.05499191e+07 -2.49172527e+06\n",
      " -2.42660728e+11 -3.92982599e+11 -4.18699019e+11 -4.18699019e+11\n",
      " -5.29443180e+11  2.06349970e+11 -5.29443180e+11  2.06349970e+11\n",
      " -3.81866262e+05  2.06349970e+11 -5.87111792e+11  1.48681357e+11\n",
      "  5.02433394e+10  5.02433394e+10  3.09847247e+10 -1.08076547e+11\n",
      " -1.08076547e+11  2.00832864e+04  3.07415896e+11  2.49747283e+11\n",
      " -5.58743063e+11  2.49747283e+11  2.49747283e+11 -7.51980505e+10\n",
      "  1.29394585e+11  2.87599329e+11  2.87599329e+11 -1.48545574e+11\n",
      " -1.27585089e+11 -1.27585089e+11  7.06920544e+11 -1.83251298e+11\n",
      " -1.63082309e+11 -1.88798729e+11  5.72710841e+11  5.85479009e+10\n",
      "  5.85479009e+10  1.25946572e+11 -6.84509277e-02  3.03955078e-02\n",
      " -1.74908341e+10 -1.74908341e+10 -1.74908341e+10 -4.32072544e+10\n",
      " -4.32072544e+10 -4.57763672e-05 -4.32072544e+10  1.33514404e-05\n",
      "  4.39350333e+10  2.87451377e+11  2.87451377e+11  2.87451377e+11\n",
      "  2.87451377e+11 -1.48545574e+11 -1.48545574e+11 -1.48545574e+11\n",
      "  2.09108070e+11  1.33321735e+10  7.49125323e+11  1.33321734e+10\n",
      "  1.33321734e+10  1.33321734e+10  1.33321735e+10  5.85479009e+10\n",
      "  5.85479009e+10  1.40645029e-05 -1.63082309e+11 -1.27585089e+11\n",
      " -3.80131701e-06 -1.27585089e+11 -1.27585089e+11 -1.85253702e+11\n",
      " -1.85253702e+11 -1.85253702e+11 -1.85253702e+11 -1.66870961e-11\n",
      " -1.85253702e+11 -1.85253702e+11 -4.47560420e+10 -4.47560420e+10\n",
      " -4.47560420e+10 -4.47560420e+10  2.83840340e+10 -1.95399252e-14\n",
      " -1.74908341e+10  1.42108547e-14 -1.74908341e+10  2.04281037e-14\n",
      " -1.74908341e+10 -1.74908341e+10  2.49275681e+11  2.49275681e+11\n",
      "  2.66453526e-15 -3.21888797e+11 -1.99840144e-14 -3.21888797e+11\n",
      " -3.21888797e+11 -2.86456758e+11 -3.52935009e+11 -2.60740337e+11\n",
      " -1.47392555e+11 -2.60740337e+11 -1.47392555e+11 -5.10702591e-15\n",
      " -3.52935009e+11 -2.60740337e+11 -1.47392555e+11 -2.60740337e+11\n",
      " -1.47392555e+11 -1.48545574e+11  1.50990331e-14 -1.48545574e+11\n",
      " -1.77845457e+11  4.00799159e+11 -1.69316687e+11 -1.69316687e+11\n",
      "  1.41731816e+11  1.88737914e-14  1.50990796e+11  8.86783946e+11\n",
      "  1.50990796e+11  2.20101715e-14  1.51138748e+11  1.51138748e+11\n",
      "  1.51138748e+11  1.51138748e+11 -3.93157729e-14  1.21838865e+11\n",
      "  1.21838865e+11  1.51138748e+11  1.51138748e+11  1.21838865e+11\n",
      "  3.87526208e+10  3.87526208e+10  3.87526208e+10  3.87526208e+10\n",
      " -1.27585089e+11 -1.27585089e+11 -1.27585089e+11 -1.27585089e+11\n",
      "  8.88178420e-15 -9.10382880e-15  7.70075463e+10  5.81841735e+11\n",
      " -1.53951415e+11 -1.53951415e+11 -4.32072544e+10 -9.17821006e+10\n",
      " -4.32072544e+10 -4.32072544e+10 -1.53951415e+11 -1.53951415e+11\n",
      " -4.32072544e+10 -4.32072544e+10 -5.10702591e-15 -9.17821005e+10\n",
      " -3.93018951e-14  2.57571742e-14  1.05868263e+09 -5.68639468e+10\n",
      " -5.68639468e+10 -5.68639468e+10  5.81639970e+10  5.81639970e+10\n",
      " -1.05475856e+11 -1.96844945e+11  0.00000000e+00 -4.62677720e+11\n",
      " -4.62677720e+11 -1.88798729e+11  8.97506559e+10  8.97506559e+10\n",
      " -1.63144469e+11 -1.59750506e+10  4.88498131e-15  3.55731384e+11\n",
      "  3.55731384e+11  5.81639970e+10  5.81639970e+10  3.23996773e+11\n",
      "  3.23996773e+11  3.23996773e+11  3.23996773e+11  3.23996773e+11\n",
      "  3.26453415e+10  3.26453415e+10  3.26453415e+10  3.26453415e+10\n",
      " -2.52772880e+10 -2.52772880e+10 -2.52772880e+10 -2.52772880e+10\n",
      "  5.82699325e+11  4.72955008e-14  5.82699325e+11  7.86004789e+10\n",
      "  7.86004789e+10  7.86004789e+10  7.86004789e+10  7.86004790e+10\n",
      "  2.30148298e+11  2.30148298e+11  2.55864718e+11 -1.37376430e+11\n",
      " -2.09785714e+11  3.23996773e+11  3.23996773e+11  3.23996773e+11\n",
      " -4.32632958e+11  2.55864718e+11  2.55864718e+11  2.55864718e+11\n",
      "  2.04405222e+10  1.01603646e+11  4.39350333e+10  2.38064227e+11\n",
      " -9.44856184e+10 -9.44856184e+10 -3.38650335e+11 -9.16407457e+10\n",
      " -9.16407457e+10  1.19404137e+11 -5.77315973e-15  1.19404137e+11\n",
      "  1.19404137e+11  5.06412204e+10  5.06412204e+10 -3.99680289e-14\n",
      " -1.63144469e+11  2.78333744e+11 -9.46465128e-15 -7.90561805e+10\n",
      " -7.90561805e+10  7.86434370e+11  5.06412204e+10  5.06412204e+10\n",
      "  5.06412204e+10  5.20601595e+11 -2.15191555e+11 -3.28842773e+11\n",
      "  4.06950377e+11  4.07193226e+10  4.13002965e-14  1.25090161e+12\n",
      "  5.15108457e+11  5.15108457e+11  3.89077905e+11  3.89077905e+11\n",
      " -1.59750507e+10 -1.59750507e+10  1.34346820e+11  3.55461102e+10\n",
      "  1.88617585e+11 -2.09785714e+11  5.60470616e+10  5.60470616e+10\n",
      "  5.60470616e+10 -7.01019870e+11 -1.42108547e-14  9.33221834e+10\n",
      "  9.33221834e+10  2.18141243e+11  5.23807793e+10  1.20485530e+11\n",
      "  1.20485530e+11  9.47691100e+10  1.20485530e+11  1.20485530e+11\n",
      "  6.66133815e-16 -2.09832152e-14 -1.63082309e+11 -1.63082309e+11\n",
      "  5.72710841e+11 -1.63082309e+11 -2.86456758e+11 -3.52935009e+11\n",
      " -2.60740337e+11 -1.47392555e+11 -2.60740337e+11 -1.47392555e+11\n",
      " -1.88825229e+11 -1.88825229e+11 -1.88825229e+11 -1.04497933e+11\n",
      " -1.04497933e+11 -4.01437580e+11 -4.01437580e+11 -4.01437580e+11\n",
      "  9.04564192e+10  9.04564192e+10  9.04564192e+10  9.04564192e+10\n",
      " -7.53040448e+10  8.16806623e+10 -6.13462527e+11 -3.47629752e+11\n",
      " -1.59750507e+10 -1.59750507e+10 -1.59750507e+10  1.34346820e+11\n",
      "  1.88617585e+11  3.07415896e+11  4.43876476e+11  4.18160056e+11\n",
      "  4.43876476e+11  1.50990796e+11 -7.51980505e+10  2.36453342e+11\n",
      "  2.36453342e+11  1.05852827e-14  2.36453342e+11  9.99927609e+10\n",
      " -3.77475828e-14 -1.67643677e-14  2.68297173e+11  9.99927609e+10\n",
      "  9.99927609e+10 -2.88657986e-15  9.04564192e+10 -3.62514293e+11\n",
      " -1.00253045e+11 -7.54421914e+10 -7.54421914e+10  8.43769499e-15\n",
      " -3.04845681e+11 -3.04845681e+11 -3.04845681e+11  5.06412204e+10\n",
      " -1.00038657e-14  5.06412204e+10  5.06412204e+10 -4.32632958e+11\n",
      " -1.36438191e+11  2.30148298e+11  2.30148298e+11  3.49801124e+11\n",
      " -1.00253045e+11  1.54205439e+11  6.02278647e+10  1.01603646e+11\n",
      "  8.97506559e+10  2.04405222e+10 -1.07244302e+11 -1.07244302e+11\n",
      "  7.77156117e-15 -2.48929075e+11 -3.35287353e-14 -2.48929075e+11\n",
      " -2.48929075e+11 -2.48929075e+11 -2.47024623e-14 -2.48929075e+11\n",
      " -2.99542890e+11  4.36250260e+11 -1.36438191e+11  3.33066907e-15\n",
      "  1.29394585e+11  2.49275681e+11  2.49275681e+11  2.49275681e+11\n",
      " -7.90561805e+10  1.15073013e+11  1.15073013e+11 -5.32907052e-15\n",
      " -2.77555756e-14 -1.69316687e+11 -2.40363285e-14  3.98570066e-14\n",
      " -8.63762593e+10 -5.90683320e+11 -5.90683320e+11  1.45109830e+11\n",
      " -1.42108547e-14  1.14756110e+11  2.51216691e+11  2.22044605e-15\n",
      "  2.25500271e+11  2.25500271e+11  2.25500271e+11 -3.24850544e+11\n",
      "  4.10942605e+11  1.14756110e+11  1.14756110e+11  3.06081158e-14\n",
      "  1.92068583e-14  2.20665131e+11  9.31063613e+10  8.54562274e+10\n",
      "  1.18793864e-14 -4.71878148e-15  4.88498131e-15  5.35159703e+10\n",
      "  3.19348746e+11 -2.79634817e+11 -2.79634817e+11 -9.68123801e+10\n",
      " -9.68123801e+10 -3.47629752e+11 -3.47629752e+11 -3.47629752e+11\n",
      " -3.47629752e+11 -3.47629752e+11 -3.47629752e+11 -3.47629752e+11\n",
      " -3.47629752e+11 -5.76205750e-14 -3.47629752e+11  5.62237172e+11\n",
      " -2.09785714e+11 -2.09785714e+11 -2.09785714e+11 -8.98720591e+11\n",
      " -4.01437580e+11 -4.01437580e+11 -4.01437580e+11 -2.13162821e-14\n",
      "  2.38064227e+11 -2.60486077e-14 -8.37480451e+11 -1.36438191e+11\n",
      " -1.36438191e+11  1.63772960e+11 -1.31238478e+11 -4.18699019e+11\n",
      " -4.18699019e+11  2.80331314e-15 -1.07244302e+11 -1.07244302e+11\n",
      " -7.72151908e+10 -7.72151907e+10 -2.11620028e+11 -2.11620028e+11\n",
      " -2.11620028e+11 -3.92982599e+11 -4.18699019e+11 -6.58057186e-15\n",
      " -5.29443180e+11  6.34694530e+10  6.34694530e+10 -5.29443180e+11\n",
      " -5.29443180e+11 -7.29911279e+10 -7.29911279e+10 -1.66715996e+11\n",
      " -1.66715996e+11 -1.66715996e+11 -1.66715996e+11 -2.72694751e+11\n",
      " -2.72694751e+11  3.28903571e-14 -2.72694751e+11 -3.30617380e+11\n",
      " -3.30617380e+11 -3.30617380e+11 -3.30617380e+11  2.69908058e+11\n",
      " -7.51980505e+10  5.60470616e+10  1.97588379e+10  1.97588379e+10\n",
      " -1.95152954e+11 -1.95152954e+11  1.10187138e+11  1.10187138e+11\n",
      "  9.58569478e+10  9.58569478e+10  9.58569478e+10  9.58569478e+10\n",
      "  9.58569478e+10  9.58569478e+10  9.58569478e+10  9.58569478e+10\n",
      "  9.58569478e+10 -1.63144469e+11 -1.05475856e+11 -1.05475856e+11\n",
      "  2.87451377e+11  1.50990796e+11  1.50990796e+11  2.87451377e+11\n",
      "  4.03635058e+10  4.03635058e+10  7.23037629e+10  7.23037629e+10\n",
      "  2.61734957e+11  4.03635058e+10  4.03635058e+10  2.85882429e-15\n",
      "  3.55731384e+11 -6.06181771e-14  3.55583431e+11  3.55583431e+11\n",
      " -1.64988269e+11 -1.64988269e+11  3.55583431e+11  3.55583431e+11\n",
      "  6.17355246e+10  6.17355246e+10  6.17355246e+10  6.17355246e+10\n",
      " -2.15589436e+11 -2.15589436e+11 -3.60783030e+11 -3.60783030e+11\n",
      " -4.99600361e-15 -1.16001709e+11 -8.37480451e+11 -8.37480451e+11\n",
      " -9.49502546e+10  6.40842895e+11  2.87143836e+11  3.48807626e+11\n",
      " -5.32907052e-15  3.48807626e+11  3.55583431e+11  3.55583431e+11\n",
      "  8.97506559e+10  3.37162728e-14  2.04405222e+10 -7.01019870e+11\n",
      " -4.18699019e+11 -2.79634817e+11  1.75415238e-14 -1.14394004e-14\n",
      " -1.66715996e+11 -1.66715996e+11 -1.89349232e+11 -1.89349232e+11\n",
      "  7.01301374e+11  7.01301374e+11  4.95758920e+11  3.09847247e+10\n",
      "  3.09847247e+10 -2.09785714e+11 -2.09785714e+11 -2.64976999e+11\n",
      "  6.12625305e+10 -4.88322968e+10 -3.07592900e-14 -2.13875680e+10\n",
      " -1.68753900e-14  2.49275681e+11  2.46175755e+11  2.46175755e+11\n",
      "  2.46175755e+11  2.46175755e+11  5.12008531e+11  5.12008531e+11\n",
      "  5.12008531e+11  5.12008531e+11  5.12008531e+11  5.17919041e-14\n",
      " -1.34231268e+11 -1.34231268e+11  1.31601508e+11  3.32890962e+11\n",
      "  3.32890962e+11  3.32890962e+11  3.32890962e+11  2.75222350e+11\n",
      "  2.75222350e+11  2.75222350e+11  2.75222350e+11  2.75222350e+11\n",
      "  2.75222350e+11  3.77156872e+11  3.77156872e+11  3.77156872e+11\n",
      "  2.22044605e-15  3.77156872e+11 -1.33226763e-15 -1.36438191e+11\n",
      "  9.34701357e+10  9.34701357e+10  9.34701357e+10  2.04405222e+10\n",
      " -6.66133815e-16 -1.20849929e+10  5.02433393e+10  5.02433393e+10\n",
      "  5.02433394e+10  5.02433394e+10  5.02433393e+10  5.02433393e+10\n",
      "  5.57224258e+11  5.57224258e+11 -8.88178420e-16 -3.38650335e+11\n",
      " -2.46455664e+11 -4.12216128e+11 -9.63272973e-16  1.94129194e+11\n",
      "  1.36460581e+11  9.21946717e+10 -3.18438308e+10  1.52903276e+11\n",
      "  1.77264239e+11 -9.29429083e+10  7.42912664e+10  1.65760464e+11\n",
      "  2.57164203e+10  1.97700721e+11 -6.81320545e+10 -1.13347782e+11\n",
      "  2.54806036e+11  3.12728665e+11  1.47386932e+00 -8.16345215e-03\n",
      " -1.96012669e+01  1.73892212e+00  2.94031723e+11 -5.99729250e+11\n",
      "  4.29090500e-01  3.26869202e+00  1.45570755e-01  5.95471382e-01\n",
      "  1.68667603e+00  6.35772705e-01 -2.17022705e+00 -5.16650147e+11\n",
      "  5.02046204e+00 -2.17826843e-01  4.13639128e+00 -1.50321871e+11\n",
      "  1.46362305e-01  1.61828613e+00  2.31620789e+00  7.35793150e+11\n",
      "  7.35793150e+11  7.35793150e+11]\n",
      "Intercept: -51471163952.58246\n",
      "Mean Squared Error: 5.718706376759083e+22\n",
      "R2 score -1.3830185622331976e+19\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(columns=['CO2EMISSIONS']) # Features (independent variables)\n",
    "y = data['CO2EMISSIONS']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "coefficients = lin_reg.coef_\n",
    "intercept = lin_reg.intercept_\n",
    "print(\"Coefficients:\", coefficients)\n",
    "print(\"Intercept:\", intercept)\n",
    "# Step 7: Make predictions\n",
    "predicted_gas_consumption = lin_reg.predict(X_test)\n",
    "# Step 8: Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, predicted_gas_consumption)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R2 score\",r2_score(y_test, predicted_gas_consumption))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "817b5ad9-48f4-4fe2-93a8-1bec8bc1f31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "         1.065e+03],\n",
       "        [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "         1.050e+03],\n",
       "        [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "         1.185e+03],\n",
       "        ...,\n",
       "        [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "         8.350e+02],\n",
       "        [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "         8.400e+02],\n",
       "        [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "         5.600e+02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'),\n",
       " 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n',\n",
       " 'feature_names': ['alcohol',\n",
       "  'malic_acid',\n",
       "  'ash',\n",
       "  'alcalinity_of_ash',\n",
       "  'magnesium',\n",
       "  'total_phenols',\n",
       "  'flavanoids',\n",
       "  'nonflavanoid_phenols',\n",
       "  'proanthocyanins',\n",
       "  'color_intensity',\n",
       "  'hue',\n",
       "  'od280/od315_of_diluted_wines',\n",
       "  'proline']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 255 Write Python code to train a kNN classifier using the following steps:\n",
    "# • Split the dataset X into training and testing sets with a test size of 0.3 and a random state of 42.\n",
    "# • Initialize a kNN classifier with 5 neighbors.\n",
    "# • Train the classifier on the training set.\n",
    "# • Make predictions on the test set.\n",
    "# • Calculate and print the accuracy score of the classifier.\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()\n",
    "x = wine.data\n",
    "y = wine.target\n",
    "wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcf8b1fb-9e33-4b80-a7ef-f6e3c1d99156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of kNN classifier: 0.74\n"
     ]
    }
   ],
   "source": [
    "# df.dtypes\n",
    "# x=df.drop(columns=['quality']) #\n",
    "# y=df['quality']\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train,y_train)\n",
    "ypred=knn.predict(x_test)\n",
    "# print(ypred)\n",
    "from sklearn.metrics import accuracy_score\n",
    "# print(accuracy_score(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, ypred)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "print(f'Accuracy of kNN classifier: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cabe2d9-9874-435e-bbac-6088d52a81aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 256 Write Python code to train a decision tree classifier with entropy as the criterion\n",
    "# using the following steps:\n",
    "# • Initialize a Decision Tree classifier with entropy as the criterion.\n",
    "# • Train the classifier on the training set.\n",
    "# • Make predictions on the test set.\n",
    "# • Calculate and print the confusion matrix for the classifier.\n",
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()\n",
    "x= wine.data\n",
    "y = wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb0b3b9c-64a1-43bb-ab9e-8101c9669ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[18  1  0]\n",
      " [ 2 17  2]\n",
      " [ 2  1 11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc=DecisionTreeClassifier(criterion=\"entropy\",random_state=42)\n",
    "dtc.fit(x_train,y_train)\n",
    "y_pred=dtc.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix=confusion_matrix(y_test,y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbb64c54-7fe3-412a-b7db-6f1202d0fcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[18  1  0]\n",
      " [ 2 17  2]\n",
      " [ 2  1 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88        19\n",
      "           1       0.89      0.81      0.85        21\n",
      "           2       0.85      0.79      0.81        14\n",
      "\n",
      "    accuracy                           0.85        54\n",
      "   macro avg       0.85      0.85      0.85        54\n",
      "weighted avg       0.86      0.85      0.85        54\n",
      "\n",
      "0.8518518518518519\n"
     ]
    }
   ],
   "source": [
    "# 257 Write Python code to evaluate the performance of a classification model using\n",
    "# the following steps:\n",
    "# • Import the necessary functions from sklearn.metrics.\n",
    "# • Calculate and print the classification report for the true labels and predicted labels.\n",
    "# • Calculate and print the accuracy score of the classifier.\n",
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()\n",
    "x= wine.data\n",
    "y = wine.target\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc=DecisionTreeClassifier(criterion=\"entropy\",random_state=42)\n",
    "dtc.fit(x_train,y_train)\n",
    "y_pred=dtc.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "matrix=confusion_matrix(y_test,y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(matrix)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b6e18f-5848-48e1-abfa-2b149ffcb8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
       "0     1            5.1           3.5            1.4           0.2   \n",
       "1     2            4.9           3.0            1.4           0.2   \n",
       "2     3            4.7           3.2            1.3           0.2   \n",
       "3     4            4.6           3.1            1.5           0.2   \n",
       "4     5            5.0           3.6            1.4           0.2   \n",
       "..  ...            ...           ...            ...           ...   \n",
       "95   96            5.7           3.0            4.2           1.2   \n",
       "96   97            5.7           2.9            4.2           1.3   \n",
       "97   98            6.2           2.9            4.3           1.3   \n",
       "98   99            5.1           2.5            3.0           1.1   \n",
       "99  100            5.7           2.8            4.1           1.3   \n",
       "\n",
       "            Species  \n",
       "0       Iris-setosa  \n",
       "1       Iris-setosa  \n",
       "2       Iris-setosa  \n",
       "3       Iris-setosa  \n",
       "4       Iris-setosa  \n",
       "..              ...  \n",
       "95  Iris-versicolor  \n",
       "96  Iris-versicolor  \n",
       "97  Iris-versicolor  \n",
       "98  Iris-versicolor  \n",
       "99  Iris-versicolor  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 258 Using the Iris dataset (Iris.csv), write Python code to perform the following\n",
    "# tasks:\n",
    "# • Split the dataset into features (X) and labels (y).\n",
    "# • Split the features and labels into training and testing sets with a test size of 0.2 and a random\n",
    "# state of 42.\n",
    "# • Initialize a kNN classifier with 3 neighbors.\n",
    "# • Train the classifier on the training set.\n",
    "# • Make predictions on the test set.\n",
    "# • Calculate and print the accuracy score of the classifier.\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"iris.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "453ad4e7-0d69-4364-978d-68603c43a9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# df.dtypes\n",
    "x=df.drop('Species',axis=1)\n",
    "y=df['Species']\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(x_train,y_train)\n",
    "y_pred=knn.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8011cb41-80c3-4038-bc2f-139e40a6175d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 259 You are tasked with using the k-Nearest Neighbors (kNN) algorithm to clas-\n",
    "# sify whether patients have diabetes or not based on certain diagnostic measurements.\n",
    "# You have been provided with diabetes.csv file. The datasets consist of several medi-\n",
    "# cal predictor (independent) variables and one target (dependent) variable, Outcome.\n",
    "# Independent variables include the number of pregnancies the patient has had, their\n",
    "# BMI, insulin level, age, and so on. Also perform Model Performance Analysis using\n",
    "# confusion matrix.\n",
    "import pandas as pd\n",
    "df=pd.read_csv('diabetes.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ec692e9-9527-4d69-a221-93c0435fd24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6623376623376623\n",
      "[[70 29]\n",
      " [23 32]]\n"
     ]
    }
   ],
   "source": [
    "# df.isna().sum()\n",
    "# df.dtypes\n",
    "x=df.drop('Outcome',axis=1)\n",
    "y=df['Outcome']\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train,y_train)\n",
    "y_pred=knn.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c8002a2-919e-4366-bf71-76203ee95b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
       "0     1            5.1           3.5            1.4           0.2   \n",
       "1     2            4.9           3.0            1.4           0.2   \n",
       "2     3            4.7           3.2            1.3           0.2   \n",
       "3     4            4.6           3.1            1.5           0.2   \n",
       "4     5            5.0           3.6            1.4           0.2   \n",
       "..  ...            ...           ...            ...           ...   \n",
       "95   96            5.7           3.0            4.2           1.2   \n",
       "96   97            5.7           2.9            4.2           1.3   \n",
       "97   98            6.2           2.9            4.3           1.3   \n",
       "98   99            5.1           2.5            3.0           1.1   \n",
       "99  100            5.7           2.8            4.1           1.3   \n",
       "\n",
       "            Species  \n",
       "0       Iris-setosa  \n",
       "1       Iris-setosa  \n",
       "2       Iris-setosa  \n",
       "3       Iris-setosa  \n",
       "4       Iris-setosa  \n",
       "..              ...  \n",
       "95  Iris-versicolor  \n",
       "96  Iris-versicolor  \n",
       "97  Iris-versicolor  \n",
       "98  Iris-versicolor  \n",
       "99  Iris-versicolor  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 260 The objective is to perform classification on the Iris dataset using the k-Nearest\n",
    "# Neighbors (kNN) algorithm. The Iris dataset contains measurements of various iris\n",
    "# flowers, including features such as sepal length, sepal width, petal length, and petal\n",
    "# width, along with the corresponding species label. The problem involves two main\n",
    "# tasks:\n",
    "# • Build a kNN classification model to predict the species of iris flowers based on their feature\n",
    "# measurements.\n",
    "# • Train the model on a portion of the dataset and evaluate its performance on another portion\n",
    "# to assess its accuracy.\n",
    "# • Experiment with different values of k and choose the optimal value that maximizes the model’s\n",
    "# performance.\n",
    "# • Use appropriate evaluation confusion matrix to evaluate the model’s performance. Also cal-\n",
    "# culate accuracy, sensitivity, and specificity.\n",
    "# Use iris.csv file for dataset.\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"iris.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94580cb7-9286-4b07-806b-1c97c0dfa0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 3\n"
     ]
    }
   ],
   "source": [
    "# df.dtypes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "\n",
    "x=df.drop('Species',axis=1)\n",
    "y=df['Species']\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "k_values = [3, 5, 7, 9]\n",
    "best_accuracy = 0\n",
    "best_k = 0\n",
    "for k in k_values:\n",
    "    knn=KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(x_train,y_train)\n",
    "    y_pred=knn.predict(x_test)\n",
    "    accuracy=accuracy_score(y_test,y_pred)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_k = k\n",
    "print(best_accuracy,best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d454bd3c-5924-4e3b-82a2-f8ab70f61813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "knn_final = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_final.fit(x_train, y_train)\n",
    "y_pred_final = knn_final.predict(x_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_final)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b2b74d7-417b-4a01-bb8f-0b179806653e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "total = conf_matrix.sum()\n",
    "accuracy = (conf_matrix[0, 0] + conf_matrix[1, 1] + conf_matrix[2, 2]) / total\n",
    "sensitivity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1] +conf_matrix[0, 2])\n",
    "specificity = (conf_matrix[1, 1] + conf_matrix[1, 2] + conf_matrix[2, 1] +conf_matrix[2, 2]) / (\n",
    "\n",
    "conf_matrix[1, 0] + conf_matrix[1, 1] + conf_matrix[2, 0] +conf_matrix[2, 2])\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca060364-33d7-489c-8f87-948b9e5a8bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9590643274853801\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94        63\n",
      "           1       0.96      0.97      0.97       108\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.96      0.95      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 59   4]\n",
      " [  3 105]]\n"
     ]
    }
   ],
   "source": [
    "# 261 Given the Breast Cancer Wisconsin (Diagnostic) dataset, the objective is to\n",
    "# build a kNN classification model that accurately predicts whether a tumor is benign\n",
    "# or malignant based on the diagnostic features provided. The model should be trained\n",
    "# on a portion of the dataset and evaluated on another portion to assess its performance.\n",
    "# The ultimate goal is to create a reliable classifier that can assist healthcare professionals\n",
    "# in diagnosing breast cancer accurately and early. Use cancer.csv file for dataset.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "x = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train_scaled,y_train)\n",
    "y_pred=knn.predict(x_test_scaled)\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793e99f1-c2b0-430d-a4e8-9d08bcef1e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 262 Given the credit card transaction dataset, the objective is to build a kNN clas-\n",
    "# sification model that accurately predicts whether a transaction is fraudulent or non-\n",
    "# fraudulent based on the transaction features provided. The model should be trained on\n",
    "\n",
    "# historical transaction data and evaluated on another portion of the dataset to assess its\n",
    "# performance. The ultimate goal is to create a reliable classifier that can automatically\n",
    "# detect fraudulent transactions and prevent financial losses for credit card companies\n",
    "# and cardholders. Use card_transdata.csv for dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b425cff9-7bdb-4a19-86c2-807557cab7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "Accuracy 0.5555555555555556\n",
      "Error Rate 0.4444444444444444\n",
      "Precision 0.6\n",
      "Sensitivity 0.6\n",
      "Specificity 0.5\n"
     ]
    }
   ],
   "source": [
    "actual = [\"Dog\",\"Dog\",\"Dog\",\"Dog\",'Dog','Cat','Cat','Cat','Cat']\n",
    "predicted = ['Dog','Cat','Cat','Dog','Dog','Dog','Cat','Dog','Cat']\n",
    "tn, fn, fp, tp = confusion_matrix(actual,predicted).ravel()[:4]\n",
    "print(tp)\n",
    "print(fp)\n",
    "print(tn)\n",
    "print(fn)\n",
    "accuracy = (tp + tn )/ 9\n",
    "print(\"Accuracy\", accuracy)\n",
    "print(\"Error Rate\", 1-accuracy)\n",
    "pre = tp/(tp+fp)\n",
    "print(\"Precision\", pre)\n",
    "sen = tp / (tp + fn)\n",
    "print(\"Sensitivity\", sen)\n",
    "spe = tn / (tn + fp)\n",
    "print(\"Specificity\", spe)\n",
    "#[[TN  FP],[FN  TP]] #upper : predicted lower : actual\n",
    "# c = confusion_matrix(y_test,y_pred)\n",
    "# TN = c[0][0]\n",
    "# FP = c[0][1]\n",
    "# FN = c[1][0]\n",
    "# TP = c[1][1]\n",
    "# print((TP+TN)/(TP + TN + FP + FN))\n",
    "# print(TP/(TP + FN))\n",
    "# print(TN/(TN + FP))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
